services:
  nginx:
    image: nginx:1.25.3-alpine
    container_name: nginx_proxy
    restart: unless-stopped
    ports:
      - "${PROJECT_PORT}:8000"
    volumes:
      - static_media_volume:/data
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/configs:/etc/nginx/templates:ro
      - ./nginx/data/static.html:/data/static.html
    env_file: .env
    depends_on:
      - auth_service
      - movies_service
      - events_service
      - user_activity_service
    networks:
      - sec_network

  admin_service:
    build: ./admin_service
    container_name: ${ADMIN_SERVICE_HOST}
    restart: unless-stopped
    expose:
      - "${ADMIN_SERVICE_PORT}"
    volumes:
      - static_media_volume:/var/www/
    env_file: .env
    depends_on:
      auth_service:
        condition: service_started
      postgres:
        condition: service_healthy
    networks:
      - sec_network

  auth_service:
    build: ./auth_service
    container_name: ${AUTH_SERVICE_HOST}
    restart: unless-stopped
    expose:
      - "${AUTH_SERVICE_PORT}"
    depends_on:
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - sec_network

  movies_service:
    build: movies_service
    container_name: ${MOVIES_SERVICE_HOST}
    restart: unless-stopped
    expose:
      - "${MOVIES_SERVICE_PORT}"
    depends_on:
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - sec_network

  redis:
    image: redis:6.2
    container_name: ${REDIS_HOST}
    command: ["redis-server", "--port", "${REDIS_PORT}", "--requirepass", "${REDIS_PASSWORD}"]
    restart: unless-stopped
    expose:
      - "${REDIS_PORT}"
    healthcheck:
      test: [ "CMD", "redis-cli", "-p", "${REDIS_PORT}", "--raw", "-a", "${REDIS_PASSWORD}", "ping" ]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 10s
    networks:
      - sec_network

  elasticsearch:
    image: elasticsearch:8.6.2
    container_name: ${ELASTIC_HOST}
    restart: unless-stopped
    environment:
      - ES_LOG_LEVEL=ERROR
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - http.port=${ELASTIC_PORT}
      - ELASTIC_USERNAME=$ELASTIC_USERNAME
      - ELASTIC_PASSWORD=$ELASTIC_PASSWORD
    expose:
      - "${ELASTIC_PORT}"
    healthcheck:
      test: [ "CMD-SHELL", "curl -s ${ELASTIC_SCHEME}://${ELASTIC_HOST}:${ELASTIC_PORT} >/dev/null || exit 1" ]
      interval: 10s
      retries: 5
      start_period: 120s
      timeout: 10s
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - sec_network

  postgres:
    image: postgres:16-alpine
    container_name: ${PG_HOST}
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${PG_NAME}
      POSTGRES_USER: ${PG_USER}
      POSTGRES_PASSWORD: ${PG_PASSWORD}
    command: ["postgres", "-c", "listen_addresses=*", "-c", "port=${PG_PORT}"]
    expose:
      - "${PG_PORT}"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${PG_USER} -d ${PG_NAME}" ]
      interval: 10s
      retries: 5
      timeout: 10s
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - sec_network

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
      - SPAN_STORAGE_TYPE=$ELASTIC_HOST
      - ES_SERVER_URLS=http://$ELASTIC_HOST:$ELASTIC_PORT
      - ES_USERNAME=$ELASTIC_USERNAME
      - ES_PASSWORD=$ELASTIC_PASSWORD
      # Отключаем верификацию SSL (если self-signed)
      - ES_TLS_SKIP_VERIFY=true
      # Определяем префикс индекса, чтобы не возникало конфликтов с другими сервисами, использующие Elasticsearch
      - ES_INDEX_PREFIX=jaegertracing
    restart: unless-stopped
    depends_on:
      - elasticsearch
    networks:
      - sec_network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - sec_network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "kafka:9092", "--list" ]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - sec_network

  events_service:
    build:
      context: ./events_service          # путь к Dockerfile
    container_name: events_service
    env_file: .env                       # Kafka, Redis, AUTH_SERVICE_URL, ...
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - sec_network                      # единая сеть со всеми сервисами
    expose:
      - "5000"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5000/health" ]
      interval: 30s
      timeout: 3s
      retries: 3

  etl_service:
    build:
      context: ./etl_service
    container_name: etl_service
    env_file: .env
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_started
      clickhouse:
        condition: service_started
      redis:
        condition: service_started
      elasticsearch:
        condition: service_started
    networks:
      - sec_network

  clickhouse:
    image: clickhouse/clickhouse-server:25.4.2
    container_name: ${CLICKHOUSE_HOST}
    environment:
      - CLICKHOUSE_DB=$CLICKHOUSE_DB
      - CLICKHOUSE_USER=$CLICKHOUSE_USER
      - CLICKHOUSE_PASSWORD=$CLICKHOUSE_PASSWORD
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    networks:
      - sec_network

  user_activity_service:
    build: user_activity_service
    container_name: ${USER_ACTIVITY_SERVICE_HOST}
    restart: unless-stopped
    expose:
      - "${USER_ACTIVITY_SERVICE_PORT}"
    depends_on:
      mongos2:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - sec_network

  mongors1n1:
    container_name: mongors1n1
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors1 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/init_files/shard1:/docker-entrypoint-initdb.d/:ro
      - ./mongo/mongo_clusters/rs1n1:/data/db
    networks:
      - sec_network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  mongors1n2:
    container_name: mongors1n2
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors1 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/rs1n2:/data/db
    networks:
      - sec_network

  mongors1n3:
    container_name: mongors1n3
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors1 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/rs1n3:/data/db
    networks:
      - sec_network

  mongors2n1:
    container_name: mongors2n1
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors2 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/init_files/shard2:/docker-entrypoint-initdb.d/:ro
      - ./mongo/mongo_clusters/rs2n1:/data/db
    networks:
      - sec_network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  mongors2n2:
    container_name: mongors2n2
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors2 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/rs2n2:/data/db
    networks:
      - sec_network

  mongors2n3:
    container_name: mongors2n3
    image: mongo:7.0
    command: mongod --shardsvr --replSet mongors2 --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/rs2n3:/data/db
    networks:
      - sec_network

  mongocfg1:
    container_name: mongocfg1
    image: mongo:7.0
    depends_on:
      - mongocfg2
    command: mongod --configsvr --replSet mongors1conf --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/init_files/config:/docker-entrypoint-initdb.d/:ro
      - ./mongo/mongo_clusters/cfg1:/data/db
    networks:
      - sec_network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  mongocfg2:
    container_name: mongocfg2
    image: mongo:7.0
    command: mongod --configsvr --replSet mongors1conf --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/cfg2:/data/db
    networks:
      - sec_network

  mongocfg3:
    container_name: mongocfg3
    image: mongo:7.0
    command: mongod --configsvr --replSet mongors1conf --dbpath /data/db --port 27017
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/mongo_clusters/cfg3:/data/db
    networks:
      - sec_network

  mongos1:
    container_name: mongos1
    image: mongo:7.0
    depends_on:
      mongocfg1:
        condition: service_healthy
    command: mongos --configdb mongors1conf/mongocfg1:27017,mongocfg2:27017,mongocfg3:27017 --port 27017 --bind_ip_all
    expose:
      - "27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
    networks:
      - sec_network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  mongos2:
    container_name: mongos2
    image: mongo:7.0
    depends_on:
      mongos1:
        condition: service_healthy
      mongors1n1:
        condition: service_healthy
      mongors2n1:
        condition: service_healthy
    command: >
      sh -c '
        if [ ! -f /init_files/.init_done ]; then
          echo "Инициализация шардированного кластера MongoDB..."
          bash /init_files/init_mongo_sharding.sh \
            || { echo "Ошибка при выполнении init_mongo_sharding.sh"; exit 1; }
          echo "Инициализация MongoDB успешно выполнена."
          touch /init_files/.init_done
        fi &&
        exec mongos \
          --configdb mongors1conf/mongocfg1:27017,mongocfg2:27017,mongocfg3:27017 \
          --port 27017 \
          --bind_ip_all
      '
    environment:
      - MONGO_NAME=${MONGO_NAME}
    expose:
      - "27017"
    ports:
      - "27017:27017"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./mongo/init_files/init_mongo_sharding.sh:/init_files/init_mongo_sharding.sh:ro
    networks:
      - sec_network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  sec_network:
    driver: bridge

volumes:
  es_data:
  pg_data:
  static_media_volume:
  clickhouse_data: